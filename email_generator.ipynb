{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eccd20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c16ff50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first person to land on the moon was Neil Armstrong. He stepped out of the lunar module Eagle and onto the moon's surface on July 20, 1969, during the Apollo 11 mission. Armstrong famously declared, \"That's one small step for man, one giant leap for mankind,\" as he became the first human to set foot on the moon.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(\n",
    "    temperature=0, \n",
    "    groq_api_key='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', \n",
    "    model_name=\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "response = llm.invoke(\"The first person to land on moon was ...\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c5fa26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.41)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.20 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.20)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langchain-community) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.11)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langchain<1.0.0,>=0.3.20->langchain-community) (0.3.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langchain<1.0.0,>=0.3.20->langchain-community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain-community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain-community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Using cached langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, marshmallow, httpx-sse, dataclasses-json, pydantic-settings, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.19 marshmallow-3.26.1 pydantic-settings-2.8.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90d33612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Safe Intelligence hiring Python Engineer in London, England, United Kingdom | LinkedIn\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "LinkedIn and 3rd parties use essential and non-essential cookies to provide, secure, analyze and improve our Services, and to show you relevant ads (including professional and job ads) on and off LinkedIn. Learn more in our Cookie Policy.Select Accept to consent or Reject to decline non-essential cookies for this use. You can update your choices at any time in your settings.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                Accept\n",
      "                \n",
      "\n",
      "                Reject\n",
      "                \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Skip to main content\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "LinkedIn\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              Python Engineer in Birmingham\n",
      " \n",
      "Expand search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This button displays the currently selected search type. When expanded it provides a list of search options that will switch the search inputs to match the current selection. \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "                        Jobs\n",
      "                    \n",
      "\n",
      "\n",
      "\n",
      "                        People\n",
      "                    \n",
      "\n",
      "\n",
      "\n",
      "                        Learning\n",
      "                    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Clear text\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Clear text\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Clear text\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Clear text\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Clear text\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Join now\n",
      "    \n",
      "\n",
      "          Sign in\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Python Engineer\n",
      "\n",
      "Safe Intelligence\n",
      "London, England, United Kingdom\n",
      "\n",
      "\n",
      "\n",
      "                Apply\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Python Engineer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                Safe Intelligence\n",
      "              \n",
      "\n",
      "\n",
      "              London, England, United Kingdom\n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "          \n",
      "\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "\n",
      "      2 weeks ago\n",
      "  \n",
      "        \n",
      "\n",
      "          182 applicants\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          See who Safe Intelligence has hired for this role\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                Apply\n",
      "      \n",
      "\n",
      "                Save\n",
      "            \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                      Report this job\n",
      "                    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Safe Intelligence is on a mission to make AI safe and reliable for anyone to use. To help us succeed, our team is looking for a Python Engineer, and we’re hoping it’s you! In this role, you’ll be involved deeply in improving the algorithms, optimising execution, usability and package architecture of our ML verification packages. This role is primarily focused on Python programming rather than Data Science. Strong Python skills are the top priority, while Machine Learning and Data Science experience are secondary. There will be opportunities to work on machine learning model training, evaluation, and deployment, as well as explore the surrounding ecosystem of tools. However, the core mission is to enhance and refine our Python-based tools and packages.We’re looking forward to having you on board!Responsibilities: The position requires a passion for science and engineering, paired with an ability to produce production ready solutions while working closely with both product and research teams. As a Safe Intelligence Python Engineer, you will:Productise a set of Python packages and tools for use in machine learning applications that build on powerful algorithms developed by the research team.Contribute towards making verification and robust-learning algorithms scalable and more efficient, and developing a clean, well-organised code-base that supports our goal of making these methods intuitive and easy to use by the wider community. Work closely with the platform team to interface and containerise the packages and toolkits for scalable deployment.Stay updated with the latest technologies and trends in Python development and actively contribute to the team's technical knowledge base.Contribute to Machine Learning related Open Source initiatives.Requirements: The technical requirements for the role are:Professional experience as a Python-based developerExperience with modern Python development techniques and design patterns.Experience with the development of highly parallelised applications using the multiprocessing library, including memory management.Proficiency in testing approaches and frameworks like pytest as well as automation tools like Github Actions or Travis CI for maintaining code quality and continuous integration/continuous deployment (CI/CD) pipelines.Proficiency with code maintenance tools and best practice including Git.Additional beneficial experience includes:Experience with widely used tools in data science and machine learning. Developers should be somewhat familiar with libraries like NumPy, pandas, scikit-learn, and PyTorch.Experience using webhooks for real-time data delivery for use in communication between toolkits and the platform.Familiarity with CUDA and optimising highly parallelised GPU-based computations are a plus.Familiarity with the end-to-end supervised training of neural networks and accompanying MLOps ecosystem are a plus.Familiarity with other programming languages and frameworks.Experience either contributing to or maintaining Python based open-source projects.Have a passion for code quality and things done right.Experience with academic research, particularly in the field of machine learning.At a personal level we’re also looking for someone who is:Passionate about delivering software to realise safe AI solutions.Deeply technical and constantly in a state of learning.Able to communicate clearly and efficiently with a variety of audiences including developers, clients, researchers, partners and executives.Fearless in getting \"hands-on\" with technology and execution.Has a strong understanding of modern software engineering processes.Comfortable with ambiguity with a drive for clarity.Collaborative with, and respectful of others on the team.Honest, straightforward and caring about each other’s well being.Why Safe Intelligence is for you: We strongly believe AI can bring great benefits to individuals and society, but these will only be achieved if the systems we build are safe to use. To meet\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "job_url = \"https://www.linkedin.com/jobs/view/4157848124/\"\n",
    "loader = WebBaseLoader(job_url)\n",
    "page_data = loader.load().pop().page_content\n",
    "page_data =page_data[:6000] #limits the page data to 6000 tokens as that is the limit\n",
    "print(page_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c27c8c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "print(len(page_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85c89a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### SCRAPED TEXT FROM WEBSITE:\n",
    "        {page_data}\n",
    "        ### INSTRUCTION:\n",
    "        The scraped text is from the career's page of a website.\n",
    "        Your job is to extract the job postings and return them in JSON format containing the \n",
    "        following keys: `role`, `experience`, `skills` and `description`.\n",
    "        Only return the valid JSON.\n",
    "        ### VALID JSON (NO PREAMBLE):    \n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "chain_extract = prompt_extract | llm \n",
    "res = chain_extract.invoke(input={'page_data':page_data})\n",
    "type(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5415fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "json_res = json_parser.parse(res.content)\n",
    "job = json_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39961ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e8a0f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Techstack</th>\n",
       "      <th>Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>React, Node.js, MongoDB</td>\n",
       "      <td>https://example.com/react-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angular,.NET, SQL Server</td>\n",
       "      <td>https://example.com/angular-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vue.js, Ruby on Rails, PostgreSQL</td>\n",
       "      <td>https://example.com/vue-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python, Django, MySQL</td>\n",
       "      <td>https://example.com/python-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Java, Spring Boot, Oracle</td>\n",
       "      <td>https://example.com/java-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flutter, Firebase, GraphQL</td>\n",
       "      <td>https://example.com/flutter-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WordPress, PHP, MySQL</td>\n",
       "      <td>https://example.com/wordpress-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Magento, PHP, MySQL</td>\n",
       "      <td>https://example.com/magento-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>React Native, Node.js, MongoDB</td>\n",
       "      <td>https://example.com/react-native-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iOS, Swift, Core Data</td>\n",
       "      <td>https://example.com/ios-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Android, Java, Room Persistence</td>\n",
       "      <td>https://example.com/android-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kotlin, Android, Firebase</td>\n",
       "      <td>https://example.com/kotlin-android-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Android TV, Kotlin, Android NDK</td>\n",
       "      <td>https://example.com/android-tv-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>iOS, Swift, ARKit</td>\n",
       "      <td>https://example.com/ios-ar-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cross-platform, Xamarin, Azure</td>\n",
       "      <td>https://example.com/xamarin-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Backend, Kotlin, Spring Boot</td>\n",
       "      <td>https://example.com/kotlin-backend-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Frontend, TypeScript, Angular</td>\n",
       "      <td>https://example.com/typescript-frontend-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Full-stack, JavaScript, Express.js</td>\n",
       "      <td>https://example.com/full-stack-js-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Machine Learning, Python, TensorFlow</td>\n",
       "      <td>https://example.com/ml-python-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DevOps, Jenkins, Docker</td>\n",
       "      <td>https://example.com/devops-portfolio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Techstack  \\\n",
       "0                React, Node.js, MongoDB   \n",
       "1               Angular,.NET, SQL Server   \n",
       "2      Vue.js, Ruby on Rails, PostgreSQL   \n",
       "3                  Python, Django, MySQL   \n",
       "4              Java, Spring Boot, Oracle   \n",
       "5             Flutter, Firebase, GraphQL   \n",
       "6                  WordPress, PHP, MySQL   \n",
       "7                    Magento, PHP, MySQL   \n",
       "8         React Native, Node.js, MongoDB   \n",
       "9                  iOS, Swift, Core Data   \n",
       "10       Android, Java, Room Persistence   \n",
       "11             Kotlin, Android, Firebase   \n",
       "12       Android TV, Kotlin, Android NDK   \n",
       "13                     iOS, Swift, ARKit   \n",
       "14        Cross-platform, Xamarin, Azure   \n",
       "15          Backend, Kotlin, Spring Boot   \n",
       "16         Frontend, TypeScript, Angular   \n",
       "17    Full-stack, JavaScript, Express.js   \n",
       "18  Machine Learning, Python, TensorFlow   \n",
       "19               DevOps, Jenkins, Docker   \n",
       "\n",
       "                                                Links  \n",
       "0                 https://example.com/react-portfolio  \n",
       "1               https://example.com/angular-portfolio  \n",
       "2                   https://example.com/vue-portfolio  \n",
       "3                https://example.com/python-portfolio  \n",
       "4                  https://example.com/java-portfolio  \n",
       "5               https://example.com/flutter-portfolio  \n",
       "6             https://example.com/wordpress-portfolio  \n",
       "7               https://example.com/magento-portfolio  \n",
       "8          https://example.com/react-native-portfolio  \n",
       "9                   https://example.com/ios-portfolio  \n",
       "10              https://example.com/android-portfolio  \n",
       "11       https://example.com/kotlin-android-portfolio  \n",
       "12           https://example.com/android-tv-portfolio  \n",
       "13               https://example.com/ios-ar-portfolio  \n",
       "14              https://example.com/xamarin-portfolio  \n",
       "15       https://example.com/kotlin-backend-portfolio  \n",
       "16  https://example.com/typescript-frontend-portfolio  \n",
       "17        https://example.com/full-stack-js-portfolio  \n",
       "18            https://example.com/ml-python-portfolio  \n",
       "19               https://example.com/devops-portfolio  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./my_portfolio.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06822957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Using cached chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from chromadb) (2.8.2)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Using cached chroma_hnswlib-0.7.6.tar.gz (32 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Using cached fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.19.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from chromadb) (4.11.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.20.1-cp312-cp312-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from chromadb) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from chromadb) (1.69.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Using cached typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.1.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from chromadb) (13.7.1)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
      "  Using cached starlette-0.46.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.12.23)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.2)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.69.1-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.20.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
      "  Using cached huggingface_hub-0.29.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.0.4-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hemal\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Using cached chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
      "Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Using cached fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
      "Using cached kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "Downloading mmh3-5.1.0-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Downloading onnxruntime-1.20.1-cp312-cp312-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 7.6/11.3 MB 39.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 33.7 MB/s eta 0:00:00\n",
      "Using cached opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\n",
      "Using cached opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
      "Using cached opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\n",
      "Using cached opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
      "Downloading posthog-3.19.0-py2.py3-none-any.whl (77 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Using cached uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Using cached google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Downloading googleapis_common_protos-1.69.1-py2.py3-none-any.whl (293 kB)\n",
      "Downloading httptools-0.6.4-cp312-cp312-win_amd64.whl (88 kB)\n",
      "Using cached huggingface_hub-0.29.2-py3-none-any.whl (468 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached starlette-0.46.0-py3-none-any.whl (71 kB)\n",
      "Downloading watchfiles-1.0.4-cp312-cp312-win_amd64.whl (285 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: chroma-hnswlib, pypika\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml): started\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for chroma-hnswlib: filename=chroma_hnswlib-0.7.6-cp312-cp312-win_amd64.whl size=160092 sha256=86bb99106f3c4b018097181d300b5ae84f66e1a0cf7bdb1c36317c153f3da58d\n",
      "  Stored in directory: c:\\users\\hemal\\appdata\\local\\pip\\cache\\wheels\\28\\29\\0e\\934c768c2e673547ec6e947e821346f4ed691a089fe046743f\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53885 sha256=0014b06bf12890a95157713c4588ba51ca8402bc36ddcfdb74d11f99c9189434\n",
      "  Stored in directory: c:\\users\\hemal\\appdata\\local\\pip\\cache\\wheels\\d5\\3d\\69\\8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "Successfully built chroma-hnswlib pypika\n",
      "Installing collected packages: pypika, monotonic, durationpy, websockets, shellingham, rsa, pyreadline3, pyproject_hooks, protobuf, opentelemetry-util-http, oauthlib, mmh3, importlib-resources, httptools, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, requests-oauthlib, posthog, opentelemetry-proto, opentelemetry-api, humanfriendly, huggingface-hub, googleapis-common-protos, google-auth, build, typer, tokenizers, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, kubernetes, fastapi, coloredlogs, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: bcrypt\n",
      "    Found existing installation: bcrypt 3.2.0\n",
      "    Uninstalling bcrypt-3.2.0:\n",
      "      Successfully uninstalled bcrypt-3.2.0\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 deprecated-1.2.18 durationpy-0.9 fastapi-0.115.11 google-auth-2.38.0 googleapis-common-protos-1.69.1 httptools-0.6.4 huggingface-hub-0.29.2 humanfriendly-10.0 importlib-resources-6.5.2 kubernetes-32.0.1 mmh3-5.1.0 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.20.1 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 posthog-3.19.0 protobuf-5.29.3 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rsa-4.9 shellingham-1.5.4 starlette-0.46.0 tokenizers-0.21.0 typer-0.15.2 uvicorn-0.34.0 watchfiles-1.0.4 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7e888d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hemal\\.cache\\chroma\\onnx_models\\all-MiniLM-L6-v2\\onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:08<00:00, 9.49MiB/s]\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient('vectorstore')\n",
    "collection = client.get_or_create_collection(name=\"portfolio\")\n",
    "\n",
    "if not collection.count():\n",
    "    for _, row in df.iterrows():\n",
    "        collection.add(documents=row[\"Techstack\"],\n",
    "                       metadatas={\"links\": row[\"Links\"]},\n",
    "                       ids=[str(uuid.uuid4())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39ad2fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/python-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/python-portfolio'}],\n",
       " [{'links': 'https://example.com/android-portfolio'},\n",
       "  {'links': 'https://example.com/flutter-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/devops-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/python-portfolio'}],\n",
       " [{'links': 'https://example.com/devops-portfolio'},\n",
       "  {'links': 'https://example.com/kotlin-backend-portfolio'}],\n",
       " [{'links': 'https://example.com/devops-portfolio'},\n",
       "  {'links': 'https://example.com/vue-portfolio'}],\n",
       " [{'links': 'https://example.com/devops-portfolio'},\n",
       "  {'links': 'https://example.com/kotlin-android-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/python-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/python-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/ios-ar-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/python-portfolio'}],\n",
       " [{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/ios-ar-portfolio'}]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = collection.query(query_texts=job['skills'], n_results=2).get('metadatas', [])\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bd36844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'Python Engineer',\n",
       " 'experience': 'Professional experience as a Python-based developer',\n",
       " 'skills': ['Python',\n",
       "  'Modern Python development techniques',\n",
       "  'Design patterns',\n",
       "  'Multiprocessing library',\n",
       "  'Pytest',\n",
       "  'Github Actions',\n",
       "  'Travis CI',\n",
       "  'Git',\n",
       "  'NumPy',\n",
       "  'pandas',\n",
       "  'scikit-learn',\n",
       "  'PyTorch',\n",
       "  'CUDA'],\n",
       " 'description': 'Safe Intelligence is looking for a Python Engineer to improve the algorithms, optimise execution, usability and package architecture of our ML verification packages. The role is primarily focused on Python programming rather than Data Science. Strong Python skills are the top priority, while Machine Learning and Data Science experience are secondary.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ccfd720",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'Modern Python development techniques',\n",
       " 'Design patterns',\n",
       " 'Multiprocessing library',\n",
       " 'Pytest',\n",
       " 'Github Actions',\n",
       " 'Travis CI',\n",
       " 'Git',\n",
       " 'NumPy',\n",
       " 'pandas',\n",
       " 'scikit-learn',\n",
       " 'PyTorch',\n",
       " 'CUDA']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = json_res\n",
    "job['skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64a97dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Expert Python Engineers for ML Verification Packages at Safe Intelligence\n",
      "\n",
      "Dear Hiring Manager at Safe Intelligence,\n",
      "\n",
      "I came across the job description for a Python Engineer at Safe Intelligence, and I'm excited to introduce AtliQ, an AI & Software Consulting company that can fulfill your requirements. With our expertise in Python development, Machine Learning, and Data Science, we're confident that our team can improve the algorithms, optimize execution, usability, and package architecture of your ML verification packages.\n",
      "\n",
      "At AtliQ, we have a strong portfolio of Python-based projects, including [https://example.com/ml-python-portfolio](https://example.com/ml-python-portfolio) and [https://example.com/python-portfolio](https://example.com/python-portfolio), which demonstrate our capabilities in Python development, Modern Python development techniques, and libraries like NumPy, pandas, and scikit-learn. Our team is well-versed in design patterns, multiprocessing library, Pytest, Github Actions, Travis CI, and Git, ensuring that we can deliver high-quality solutions.\n",
      "\n",
      "Our expertise in PyTorch and CUDA can help optimize the execution of your ML verification packages. We understand that strong Python skills are the top priority, and our team is committed to delivering exceptional results. While Machine Learning and Data Science experience are secondary, our team has a solid foundation in these areas, which can be leveraged to improve your ML verification packages.\n",
      "\n",
      "We'd love to discuss how AtliQ can support Safe Intelligence in achieving its goals. Please let us know if you're interested in scheduling a call to explore further.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Mohan\n",
      "Business Development Executive\n",
      "AtliQ\n"
     ]
    }
   ],
   "source": [
    "prompt_email = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### JOB DESCRIPTION:\n",
    "        {job_description}\n",
    "        \n",
    "        ### INSTRUCTION:\n",
    "        You are Mohan, a business development executive at AtliQ. AtliQ is an AI & Software Consulting company dedicated to facilitating\n",
    "        the seamless integration of business processes through automated tools. \n",
    "        Over our experience, we have empowered numerous enterprises with tailored solutions, fostering scalability, \n",
    "        process optimization, cost reduction, and heightened overall efficiency. \n",
    "        Your job is to write a cold email to the client regarding the job mentioned above describing the capability of AtliQ \n",
    "        in fulfilling their needs.\n",
    "        Also add the most relevant ones from the following links to showcase Atliq's portfolio: {link_list}\n",
    "        Remember you are Mohan, BDE at AtliQ. \n",
    "        Do not provide a preamble.\n",
    "        ### EMAIL (NO PREAMBLE):\n",
    "        \n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "chain_email = prompt_email | llm\n",
    "res = chain_email.invoke({\"job_description\": str(job), \"link_list\": links})\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c514ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
